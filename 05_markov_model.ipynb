{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive approach to weather forecasting is to make the assumption that the probabilities of weather states are uncorrelated: if we have a long term estimate of the number of rainy days, versus snowy days, versus sunny days, we can simply make an estimate based on their long term probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4375006  0.38541697 0.17708243]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import numpy as np\n",
    "N_sunny = 159.6875\n",
    "N_rainy = 140.677\n",
    "N_snowy = 64.635\n",
    "\n",
    "p = np.array([N_sunny,N_rainy,N_snowy])\n",
    "p/=p.sum()  # 365\n",
    "print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict tomorrow's weather (or any day's weather), we just sample from that distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowy\n"
     ]
    }
   ],
   "source": [
    "weather_tomorrow = np.random.choice(['Sunny','Rainy','Snowy'],p=p)\n",
    "print(weather_tomorrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could produce our long-term forecast by just sampling randomly over many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sunny' 'Sunny' 'Sunny' 'Rainy' 'Rainy' 'Rainy' 'Rainy' 'Snowy' 'Sunny'\n",
      " 'Sunny' 'Rainy' 'Snowy' 'Rainy' 'Snowy' 'Sunny' 'Sunny' 'Rainy' 'Sunny'\n",
      " 'Sunny' 'Sunny' 'Rainy' 'Sunny' 'Rainy' 'Rainy' 'Rainy' 'Snowy' 'Snowy'\n",
      " 'Rainy' 'Rainy' 'Rainy' 'Rainy' 'Sunny' 'Sunny' 'Sunny' 'Sunny' 'Rainy'\n",
      " 'Sunny' 'Sunny' 'Rainy' 'Snowy' 'Sunny' 'Snowy' 'Sunny' 'Sunny' 'Rainy'\n",
      " 'Sunny' 'Sunny' 'Sunny' 'Sunny' 'Sunny']\n",
      "0.433 0.43750059931588947\n"
     ]
    }
   ],
   "source": [
    "weather = np.random.choice(['Sunny','Rainy','Snowy'],10000,p=p)\n",
    "print(weather[:50])\n",
    "print(sum(weather=='Sunny')/len(weather),p[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly a silly model for short term forecasting (although quite close to what is actually used for long-term forecasting).  \n",
    "\n",
    "A better model might be that the weather tomorrow is predicted by the weather today, or \n",
    "$$\n",
    "W_{t+1} = f(W_t).\n",
    "$$\n",
    "Imagine that we collected long-term statistics, and found that there is a so-called *transition matrix* given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.5,0.4,0.1],\n",
    "              [0.2,0.5,0.3],\n",
    "              [0.8,0.1,0.1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where entry $A_{kj}$ represents the probability of tomorrow's state being the $j$-th state, given that we are in the $k$-th state now.  Thus, if use the ordering Sunny,Rainy,Snowy, we have that the probability that it will be snowy tomorrow if it's sunny today is 0.1, the probability that it will get sunny tomorrow if it's snowing today is 0.8, and so on.  Then we can write the probability model as \n",
    "$$ P(W_{t+1}=w_j|W_t=w_k) = A_{kj} $$\n",
    "\n",
    "Now if we want to make a prediction of tomorrow's state, we can use this transition matrix.  Let's imagine that today's weather is observed to be sunny, which gives us the row vector\n",
    "$$\n",
    "P(W_t) = [1,0,0].\n",
    "$$\n",
    "To assess the probability of tomorrow's weather, we can (right)-multiply this by the transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.4, 0.1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PW_t = np.array([1,0,0])\n",
    "np.dot(PW_t,A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the most probable case for the weather tomorrow is again sunny, which we could have read from our transition matrix.  What about the weather after two days?  One of the nice properties of the transition matrix is that we can make predictions later by taking powers of the transition matrix:  $(A\\times A)_{kj}$ is the probability that we will be in state $k$ in two days, given that we are in state $j$ now.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41, 0.41, 0.18])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(PW_t,np.dot(A,A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our probabilities are more ambiguous.  As it turns out, as we take powers of the transition matrix, it converges to the long term probabilities of each state, the so-called stable distribution.  If had a long term record of the data, we could compute this empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4375    , 0.38541667, 0.17708333])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A100 = np.copy(A)\n",
    "for i in range(100):\n",
    "    A100 = np.dot(A100,A)#map_reduce(np.dot,[A]*100)\n",
    "np.dot(PW_t,A100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the columns of $A$, we'll see that they are constants.  If we multiply any vector that sums to one (as our weather probabilities must) by this matrix, we'll just get the columns back again.  Thus, our initial data, that the weather was sunny, has diffused away, and our estimate reverts back to the frequencies from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4375     0.38541667 0.17708333]\n",
      "[0.4375006  0.38541697 0.17708243]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(PW_t,A100))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, taking high powers of the transition matrix is wasteful.  A better way is to recognize that for a stable state:\n",
    "$$\n",
    "P(W_{t+1}) = P(W_{t}) = P(W_{t}) A,\n",
    "$$\n",
    "which is to say that applying the transition matrix doesn't change our state probabilities.  A way to compute this special state (we'll call it $P(\\hat{W}_t)$) is more easily seen by taking the transpose and defining $\\lambda=1$:\n",
    "$$\n",
    "A^T P(\\hat{W}_t) = \\lambda P(\\hat{W}_t).\n",
    "$$\n",
    "This is the equation for an eigenvector/value pair, with the eigenvalue fixed at 1 (a matrix where all the columns sum to one is guaranteed to have one of its eigenvalues be one).  We can compute this easily: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,v = np.linalg.eig(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvectors are non-unique, so we can just normalize the eigenvector associated with $\\lambda=1$ to one, which leaves us the steady probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000009\n",
      "[0.4375     0.38541667 0.17708333]\n"
     ]
    }
   ],
   "source": [
    "print (w[0].real)\n",
    "p_stable = v[:,0].real/v[:,0].sum(axis=0).real\n",
    "print (p_stable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are the same as those we got by taking high powers of $A$.\n",
    "\n",
    "Now let's use the transition matrix $A$ to generate some data.  We can initialize with our observation of today's weather as a prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Sunny','Rainy','Snowy']\n",
    "W_i = 'Sunny'\n",
    "weather_log = [W_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can simply loop over the number of days that we want to predict, and draw randomly based on our probability table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    W_i = np.random.choice(states,p=A[states.index(W_i)])\n",
    "    weather_log.append(W_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sunny', 'Rainy', 'Sunny', 'Rainy', 'Snowy', 'Sunny', 'Rainy', 'Rainy', 'Snowy', 'Sunny', 'Sunny', 'Snowy', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Rainy', 'Sunny', 'Snowy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Snowy', 'Rainy', 'Rainy', 'Snowy', 'Sunny', 'Sunny', 'Snowy', 'Sunny', 'Sunny', 'Snowy', 'Sunny', 'Rainy', 'Snowy', 'Sunny', 'Sunny', 'Rainy', 'Snowy', 'Sunny', 'Snowy', 'Sunny', 'Sunny', 'Rainy', 'Rainy', 'Rainy', 'Rainy', 'Rainy', 'Rainy']\n"
     ]
    }
   ],
   "source": [
    "print(weather_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick glance at this data indicates that after a snowy day, the weather almost invariably becomes sunny again, etc.  Thus the Markov model lets us model random sequences in which there should be explicit time dependency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
